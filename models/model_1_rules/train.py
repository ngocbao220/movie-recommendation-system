import sys
import os
import time
import shutil
import gc
from pyspark.sql import SparkSession
from pyspark.ml.fpm import FPGrowth
from pyspark.sql import functions as F

# --- Cáº¤U HÃŒNH ---
INPUT_PATH = "data/processed/model1_rules"
OUTPUT_PATH = "checkpoints/model_1_rulesv4/rules.parquet" # Äá»•i tÃªn folder v3
TEMP_DIR = os.path.join(os.getcwd(), "spark_temp_data") 

# --- Cáº¤U HÃŒNH "GROWTH MODE" (PHONG PHÃš HÆ N) ---

# 1. DÃ¹ng 100% dá»¯ liá»‡u (Quan trá»ng nháº¥t Ä‘á»ƒ luáº­t chÃ­nh xÃ¡c)
USER_SAMPLE_FRACTION = 1.0 

# 2. Giáº£m Support xuá»‘ng 2% Ä‘á»ƒ báº¯t Ä‘Æ°á»£c nhiá»u phim hÆ¡n
MIN_SUPPORT = 0.015

# 3. Giáº£m Confidence xuá»‘ng 20% Ä‘á»ƒ luáº­t Ä‘a dáº¡ng hÆ¡n
MIN_CONFIDENCE = 0.4    

# 4. TÄƒng Lift lÃªn 1.2 chÃºt Ä‘á»ƒ lá»c bá»›t luáº­t "nháº£m" (trÃ¹ng ngáº«u nhiÃªn)
# Luáº­t phong phÃº cáº§n Ä‘i Ä‘Ã´i vá»›i cháº¥t lÆ°á»£ng, Lift > 1.2 lÃ  ngÆ°á»¡ng Ä‘áº¹p.
MIN_LIFT = 2.0           

# 5. Giá»¯ nguyÃªn giá»›i háº¡n 50 phim/user Ä‘á»ƒ báº£o vá»‡ RAM
MAX_ITEMS_PER_USER = 50   

def main():
    # Dá»n dáº¹p temp cÅ©
    if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
    os.makedirs(TEMP_DIR)

    print(f"ğŸš€ Khá»Ÿi Ä‘á»™ng Spark (Growth Mode - Full Data)...")
    
    spark = SparkSession.builder \
        .appName("Train_Rules_Growth") \
        .config("spark.driver.memory", "6g") \
        .config("spark.executor.memory", "6g") \
        .config("spark.sql.shuffle.partitions", "200") \
        .config("spark.driver.maxResultSize", "2g") \
        .config("spark.memory.fraction", "0.6") \
        .config("spark.memory.storageFraction", "0.2") \
        .config("spark.local.dir", TEMP_DIR) \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("WARN")
    spark.sparkContext.setCheckpointDir(os.path.join(TEMP_DIR, "checkpoints"))

    print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u...")
    if not os.path.exists(INPUT_PATH): return

    df = spark.read.parquet(INPUT_PATH)
    
    print(f"âœ‚ï¸ Äang xá»­ lÃ½ dá»¯ liá»‡u (Full Data, MaxItems={MAX_ITEMS_PER_USER})...")
    
    # 1. Láº¥y máº«u (DÃ¹ng 100% data náº¿u fraction = 1.0)
    if USER_SAMPLE_FRACTION < 1.0:
        df = df.sample(withReplacement=False, fraction=USER_SAMPLE_FRACTION, seed=42)
    
    # 2. Slicing & Deduplicate
    df_clean = df.withColumn("items_distinct", F.array_distinct(F.col("items"))) \
                 .withColumn("items_sliced", F.slice(F.col("items_distinct"), 1, MAX_ITEMS_PER_USER)) \
                 .select(F.col("items_sliced").alias("items"))
    
    # 3. Repartition
    df_clean = df_clean.repartition(200)
    
    # 4. Checkpoint (An toÃ n bá»™ nhá»›)
    df_clean = df_clean.checkpoint()
    
    count = df_clean.count()
    print(f"âœ… Sáºµn sÃ ng train: {count} users.")

    print(f"ğŸ›   Train FPGrowth (Supp={MIN_SUPPORT}, Conf={MIN_CONFIDENCE})...")
    start_time = time.time()
    
    fp = FPGrowth(itemsCol="items", 
                  minSupport=MIN_SUPPORT, 
                  minConfidence=MIN_CONFIDENCE)
    
    try:
        model = fp.fit(df_clean)
        print(f"â±  Train xong trong {round(time.time() - start_time, 2)} giÃ¢y.")

        print("ğŸ’¾ Äang lá»c vÃ  lÆ°u káº¿t quáº£...")
        rules = model.associationRules
        
        # Lá»c luáº­t ngay trÃªn luá»“ng xá»­ lÃ½
        rules = rules.filter(F.size(F.col("antecedent")) <= 2)
        rules = rules.filter(F.col("lift") >= MIN_LIFT)
        rules = rules.filter(F.col("support") >= 0.005)
        
        # Chia nhá» file Ä‘áº§u ra Ä‘á»ƒ trÃ¡nh lá»—i ghi Ä‘Ä©a
        rules = rules.repartition(5)
        
        rules.write.mode("overwrite").parquet(OUTPUT_PATH)
        print(f"âœ… LÆ¯U THÃ€NH CÃ”NG Táº I: {OUTPUT_PATH}")
        print(f"   (Tham sá»‘: Supp={MIN_SUPPORT}, Conf={MIN_CONFIDENCE}, Full Data)")
        
        # Kiá»ƒm tra nhanh
        saved = spark.read.parquet(OUTPUT_PATH)
        print(f"ğŸ‰ Sá»‘ luáº­t tÃ¬m Ä‘Æ°á»£c: {saved.count()}")
        
        # Dá»n dáº¹p
        if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)

    except Exception as e:
        print(f"âŒ Lá»–I: {e}")

    spark.stop()

if __name__ == "__main__":
    main()