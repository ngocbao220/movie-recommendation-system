import sys
import os
import time
from pyspark.sql import SparkSession
from pyspark.ml.fpm import FPGrowth
from pyspark.sql import functions as F

# --- C·∫§U H√åNH ---
INPUT_PATH = "data/processed/model1_rules"
OUTPUT_PATH = "models/model_1_rules/artifacts/rules.parquet"

# TƒÇNG L√äN 0.05 ƒê·ªÇ CH·∫†Y NHANH H∆†N (Test lu·ªìng)
# Sau khi ch·∫°y th√†nh c√¥ng, b·∫°n c√≥ th·ªÉ gi·∫£m xu·ªëng 0.02 sau
MIN_SUPPORT = 0.05 
MIN_CONFIDENCE = 0.1

def main():
    print("üöÄ ƒêang kh·ªüi ƒë·ªông Spark cho Training Model 1...")
    spark = SparkSession.builder \
        .appName("Train_Model_1_Rules") \
        .config("spark.driver.memory", "8g") \
        .config("spark.executor.memory", "8g") \
        .config("spark.sql.shuffle.partitions", "100") \
        .getOrCreate()

    print(f"üìÇ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ {INPUT_PATH}...")
    if not os.path.exists(INPUT_PATH):
        print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y data.")
        return

    df = spark.read.parquet(INPUT_PATH)
    
    # --- B∆Ø·ªöC QUAN TR·ªåNG: CLEAN TR∆Ø·ªöC, CACHE SAU ---
    print("üßπ ƒêang lo·∫°i b·ªè phim tr√πng l·∫∑p...")
    df_clean = df.withColumn("items", F.array_distinct(F.col("items")))

    print("üíæ ƒêang n·∫°p d·ªØ li·ªáu v√†o RAM (Caching)...")
    # Cache d·ªØ li·ªáu s·∫°ch ƒë·ªÉ FPGrowth d√πng ƒëi d√πng l·∫°i
    df_clean.cache()
    
    # G·ªçi count() ƒë·ªÉ √âP Spark th·ª±c thi vi·ªác cache ngay l·∫≠p t·ª©c
    count = df_clean.count()
    print(f"‚úÖ ƒê√£ cache xong {count} d√≤ng d·ªØ li·ªáu v√†o RAM.")

    # --- TRAIN ---
    print(f"üõ†  B·∫Øt ƒë·∫ßu Train FPGrowth (Support: {MIN_SUPPORT})...")
    start_time = time.time()
    
    fp = FPGrowth(itemsCol="items", 
                  minSupport=MIN_SUPPORT, 
                  minConfidence=MIN_CONFIDENCE)

    model = fp.fit(df_clean)
    
    print(f"‚è±  Train xong trong {round(time.time() - start_time, 2)} gi√¢y.")

    # --- K·∫æT QU·∫¢ ---
    rules = model.associationRules
    rule_count = rules.count()
    print(f"üéâ ƒê√£ t√¨m th·∫•y {rule_count} lu·∫≠t k·∫øt h·ª£p!")

    if rule_count > 0:
        print("--- Top 5 lu·∫≠t m·∫°nh nh·∫•t ---")
        rules.sort(F.col("lift").desc()).show(5, truncate=False)
        
        print(f"üíæ ƒêang l∆∞u lu·∫≠t v√†o {OUTPUT_PATH}...")
        rules.write.mode("overwrite").parquet(OUTPUT_PATH)
        print("‚úÖ L∆∞u th√†nh c√¥ng!")
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y lu·∫≠t n√†o. H√£y gi·∫£m minSupport.")

    spark.stop()

if __name__ == "__main__":
    main()