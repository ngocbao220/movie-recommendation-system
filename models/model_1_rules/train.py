import sys
import os
from pyspark.sql import SparkSession
from pyspark.ml.fpm import FPGrowth
from pyspark.sql import functions as F

# --- Cáº¤U HÃŒNH ---
# ÄÆ°á»ng dáº«n input (Ä‘áº§u ra cá»§a bÆ°á»›c process_data vá»«a rá»“i)
INPUT_PATH = "data/processed/model1_rules"
# ÄÆ°á»ng dáº«n output (nÆ¡i lÆ°u file luáº­t káº¿t quáº£)
OUTPUT_PATH = "models/model_1_rules/artifacts/rules.parquet"

# Tham sá»‘ mÃ´ hÃ¬nh
# minSupport=0.02: Phim/Cáº·p phim pháº£i xuáº¥t hiá»‡n trong 2% sá»‘ lÆ°á»£ng giao dá»‹ch (khoáº£ng 32M * 0.02 user)
MIN_SUPPORT = 0.02 
# minConfidence=0.1: Náº¿u xem A, cÃ³ Ã­t nháº¥t 10% kháº£ nÄƒng xem B
MIN_CONFIDENCE = 0.1

def main():
    print("ğŸš€ Äang khá»Ÿi Ä‘á»™ng Spark cho Training Model 1...")
    spark = SparkSession.builder \
        .appName("Train_Model_1_Rules") \
        .config("spark.driver.memory", "8g") \
        .config("spark.executor.memory", "8g") \
        .getOrCreate()

    # 1. Load dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
    print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»« {INPUT_PATH}...")
    if not os.path.exists(INPUT_PATH):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c {INPUT_PATH}. HÃ£y cháº¡y process_data.py trÆ°á»›c!")
        return

    df = spark.read.parquet(INPUT_PATH)
    # Dá»¯ liá»‡u lÃºc nÃ y cÃ³ dáº¡ng: [userId, items (Array[String])]
    
    print("ğŸ§¹ Äang loáº¡i bá» cÃ¡c phim trÃ¹ng láº·p trong tá»«ng user transaction...")
    # array_distinct: HÃ m nÃ y sáº½ biáº¿n ['A', 'B', 'A'] thÃ nh ['A', 'B']
    df = df.withColumn("items", F.array_distinct(F.col("items")))
    
    # Cache Ä‘á»ƒ cháº¡y nhanh hÆ¡n
    df.cache()
    print(f"âœ… ÄÃ£ load {df.count()} giao dá»‹ch (user baskets).")

    # 2. Äá»‹nh nghÄ©a thuáº­t toÃ¡n FPGrowth
    print(f"ğŸ›   Äang cáº¥u hÃ¬nh FPGrowth (Support: {MIN_SUPPORT}, Confidence: {MIN_CONFIDENCE})...")
    fp = FPGrowth(itemsCol="items", 
                  minSupport=MIN_SUPPORT, 
                  minConfidence=MIN_CONFIDENCE)

    # 3. Train (Giai Ä‘oáº¡n tá»‘n thá»i gian nháº¥t)
    print("â³ Äang train mÃ´ hÃ¬nh (viá»‡c nÃ y cÃ³ thá»ƒ máº¥t vÃ i phÃºt)...")
    model = fp.fit(df)

    # 4. Láº¥y káº¿t quáº£ luáº­t káº¿t há»£p
    # Káº¿t quáº£ gá»“m cÃ¡c cá»™t: antecedents (nguyÃªn nhÃ¢n), consequents (káº¿t quáº£), confidence, lift, support
    rules = model.associationRules
    
    rule_count = rules.count()
    print(f"ğŸ‰ ÄÃ£ tÃ¬m tháº¥y {rule_count} luáº­t káº¿t há»£p!")

    if rule_count == 0:
        print("âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y luáº­t nÃ o. HÃ£y thá»­ GIáº¢M minSupport xuá»‘ng tháº¥p hÆ¡n (vd: 0.01).")
    else:
        # Xem thá»­ 5 luáº­t máº¡nh nháº¥t (theo Lift)
        print("--- Top 5 luáº­t máº¡nh nháº¥t ---")
        rules.sort(F.col("lift").desc()).show(5, truncate=False)

        # 5. LÆ°u káº¿t quáº£
        print(f"ğŸ’¾ Äang lÆ°u luáº­t vÃ o {OUTPUT_PATH}...")
        # LÆ°u Ä‘Ã¨ (overwrite) náº¿u file Ä‘Ã£ tá»“n táº¡i
        rules.write.mode("overwrite").parquet(OUTPUT_PATH)
        print("âœ… LÆ°u thÃ nh cÃ´ng!")

    spark.stop()

if __name__ == "__main__":
    main()