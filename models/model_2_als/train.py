import os
import sys
from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS, ALSModel
from pyspark.ml.evaluation import RegressionEvaluator

# --- Cáº¤U HÃŒNH ---
INPUT_PATH = "data/processed/model2_als"
OUTPUT_PATH = "outputs/model_2_als"

def check_model_exists():
    """Kiá»ƒm tra xem thÆ° má»¥c model Ä‘Ã£ tá»“n táº¡i vÃ  cÃ³ ná»™i dung chÆ°a"""
    if os.path.exists(OUTPUT_PATH):
        # Kiá»ƒm tra xem folder cÃ³ chá»©a metadata/data (Ä‘áº·c trÆ°ng cá»§a Spark model) khÃ´ng
        if os.path.exists(os.path.join(OUTPUT_PATH, "metadata")):
            return True
    return False

def main():
    # 1. KIá»‚M TRA MODEL TRÆ¯á»šC
    if check_model_exists():
        print(f"âœ… Model ALS Ä‘Ã£ tá»“n táº¡i táº¡i '{OUTPUT_PATH}'.")
        
        # Náº¿u cháº¡y trong Docker hoáº·c mÃ´i trÆ°á»ng tá»± Ä‘á»™ng
        if not sys.stdin.isatty():
            print("ğŸ¤– Docker detected: Bá» qua bÆ°á»›c training.")
            return
            
        # Náº¿u cháº¡y thá»§ cÃ´ng bÃªn ngoÃ i
        retrain = input("â“ Báº¡n cÃ³ muá»‘n train láº¡i khÃ´ng? (y/n): ").lower()
        if retrain != 'y':
            print("ğŸš€ Sá»­ dá»¥ng model cÅ©. Káº¿t thÃºc.")
            return

    # 2. KHá»I Táº O SPARK (Chá»‰ khá»Ÿi táº¡o khi thá»±c sá»± cáº§n train)
    print("ğŸš€ Äang khá»Ÿi Ä‘á»™ng Spark cho Model 2 (ALS)...")
    spark = SparkSession.builder \
        .appName("Train_Model_2_ALS") \
        .config("spark.driver.memory", "8g") \
        .config("spark.executor.memory", "8g") \
        .getOrCreate()

    try:
        # 3. Load dá»¯ liá»‡u
        if not os.path.exists(INPUT_PATH):
            print(f"âŒ Lá»—i: KhÃ´ng tháº¥y dá»¯ liá»‡u Ä‘áº§u vÃ o táº¡i {INPUT_PATH}")
            return

        print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»« {INPUT_PATH}...")
        df = spark.read.parquet(INPUT_PATH)
        
        # Chia táº­p train/test
        (training, test) = df.randomSplit([0.8, 0.2], seed=42)
        training.cache()
        print(f"âœ… ÄÃ£ load dá»¯ liá»‡u. Training set: {training.count()} dÃ²ng.")

        # 4. Cáº¥u hÃ¬nh thuáº­t toÃ¡n ALS
        als = ALS(maxIter=10, 
                  rank=10,
                  regParam=0.1, 
                  userCol="userId", 
                  itemCol="movieId", 
                  ratingCol="rating",
                  coldStartStrategy="drop",
                  nonnegative=True)

        # 5. Train
        print("â³ Äang train mÃ´ hÃ¬nh ALS (Matrix Factorization)...")
        model = als.fit(training)

        # 6. ÄÃ¡nh giÃ¡ lá»—i (RMSE)
        print("ğŸ“Š Äang Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p Test...")
        predictions = model.transform(test)
        evaluator = RegressionEvaluator(metricName="rmse", labelCol="rating", predictionCol="prediction")
        rmse = evaluator.evaluate(predictions)
        
        print(f"ğŸ‰ Káº¿t quáº£: Root-mean-square error (RMSE) = {rmse:.4f}")

        # 7. LÆ°u Model
        print(f"ğŸ’¾ Äang lÆ°u model vÃ o {OUTPUT_PATH}...")
        model.write().overwrite().save(OUTPUT_PATH)
        print("âœ… LÆ°u thÃ nh cÃ´ng!")

    except Exception as e:
        print(f"âŒ Lá»—i khi training: {e}")
    finally:
        spark.stop()
        print("ğŸ”Œ Spark Session Ä‘Ã£ Ä‘Ã³ng.")

if __name__ == "__main__":
    main()