import os
from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALSModel
from pyspark.sql.functions import col

# --- Cáº¤U HÃŒNH ---
MODEL_PATH = "models/model_2_als/artifacts/als_model"
MOVIES_CSV = "data/raw/movies.csv"
RATINGS_CSV = "data/raw/ratings.csv"

class ALSRecommender:
    def __init__(self):
        self.spark = SparkSession.builder.getOrCreate()
        self.model = None
        self.df_movies = None
        self.df_movie_counts = None # ThÃªm cÃ¡i nÃ y Ä‘á»ƒ Ä‘áº¿m view
        self.load_model()

    def load_model(self):
        if os.path.exists(MODEL_PATH):
            try:
                print("â³ Äang load Model vÃ  Dá»¯ liá»‡u phá»¥ trá»£...")
                self.model = ALSModel.load(MODEL_PATH)
                
                # Load Movies
                self.df_movies = self.spark.read.csv(MOVIES_CSV, header=True, inferSchema=True)
                
                # --- BÆ¯á»šC Má»šI: TÃNH Äá»˜ PHá»” BIáº¾N ---
                # Load Ratings Ä‘á»ƒ Ä‘áº¿m xem má»—i phim cÃ³ bao nhiÃªu ngÆ°á»i vote
                df_ratings = self.spark.read.csv(RATINGS_CSV, header=True, inferSchema=True)
                
                # Äáº¿m sá»‘ lÆ°á»£ng rating cho má»—i phim
                self.df_movie_counts = df_ratings.groupBy("movieId").count()
                
                # Join sáºµn tÃªn phim vÃ  sá»‘ lÆ°á»£ng vote láº¡i vá»›i nhau Ä‘á»ƒ tra cá»©u cho nhanh
                # Chá»‰ giá»¯ láº¡i phim nÃ o cÃ³ trÃªn 100 lÆ°á»£t vote (Con sá»‘ nÃ y tÃ¹y báº¡n chá»‰nh)
                self.df_movies = self.df_movies.join(self.df_movie_counts, "movieId") \
                                               .filter(col("count") >= 100) 
                
                self.df_movies.cache()
                print("âœ… Model 2 (ALS): ÄÃ£ load xong. ÄÃ£ lá»c bá» cÃ¡c phim dÆ°á»›i 100 vote.")
            except Exception as e:
                print(f"âŒ Lá»—i: {e}")
        else:
            print("âš ï¸ ChÆ°a cÃ³ Model.")

    def recommend_for_user(self, user_id, top_k=5):
        if self.model is None: return []

        user_df = self.spark.createDataFrame([(user_id,)], ["userId"])
        
        # Láº¥y nhiá»u hÆ¡n top_k (vÃ­ dá»¥ 100 phim) Ä‘á»ƒ sau Ä‘Ã³ lá»c láº¡i nhá»¯ng phim phá»• biáº¿n
        recs_df = self.model.recommendForUserSubset(user_df, 100)
        
        rec_list = recs_df.select("recommendations").collect()
        if not rec_list or not rec_list[0].recommendations: return []
            
        final_results = []
        # Láº¥y danh sÃ¡ch ID phim Ä‘Æ°á»£c gá»£i Ã½
        raw_recs = rec_list[0].recommendations
        
        for row in raw_recs:
            movie_id = row.movieId
            predicted_rating = row.rating
            
            # Tra cá»©u trong danh sÃ¡ch phim ÄÃƒ Lá»ŒC (trÃªn 100 view)
            movie_info = self.df_movies.filter(col("movieId") == movie_id).first()
            
            # Náº¿u tÃ¬m tháº¥y (tá»©c lÃ  phim nÃ y Ä‘á»§ phá»• biáº¿n)
            if movie_info:
                final_results.append({
                    "movie": movie_info['title'],
                    "genres": movie_info['genres'],
                    "score": round(predicted_rating, 2),
                    "votes": movie_info['count'] # Hiá»ƒn thá»‹ thÃªm sá»‘ vote cho uy tÃ­n
                })
            
            # Náº¿u Ä‘Ã£ gom Ä‘á»§ sá»‘ lÆ°á»£ng cáº§n thiáº¿t thÃ¬ dá»«ng
            if len(final_results) >= top_k:
                break
            
        return final_results

# Test thá»­
if __name__ == "__main__":
    rec = ALSRecommender()
    print("\nğŸ”® --- Káº¾T QUáº¢ Gá»¢I Ã (ÄÃ£ lá»c phim hiáº¿m) ---")
    results = rec.recommend_for_user(1, top_k=10)
    for item in results:
        print(f"ğŸ¬ {item['movie']}")
        print(f"   Score: {item['score']} | Votes: {item['votes']} | Genres: {item['genres']}")
        print("-" * 30)